{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from collections import defaultdict\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "script_links = []\n",
    "with urlopen('https://www.livesinabox.com/friends/scripts.shtml') as res:\n",
    "    soup = BeautifulSoup(res, 'html.parser')\n",
    "    for anchor in soup.find_all('a'):\n",
    "        if 'Episode ' in anchor.get_text() and any(s not in anchor.get_text() for s in ['Guide']):\n",
    "            # print(anchor.get('href'))\n",
    "            script_links.append(anchor.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = 'https://www.livesinabox.com/friends/'\n",
    "\n",
    "def get_season(link) -> int:\n",
    "    if 'season' in link:\n",
    "        season_num = int(link.lstrip(\"season\").split(\"/\")[0])\n",
    "    else:\n",
    "        season_num = 10\n",
    "    return season_num\n",
    "\n",
    "\n",
    "def get_episode(link) -> int:\n",
    "    if link == 'season9/0923-0924.html':\n",
    "        episode = 23\n",
    "    if 'season' in link:\n",
    "        episode = int(re.search('/\\d*', link).group()[2:])\n",
    "    else:\n",
    "        episode = int(link[2:4])\n",
    "    return episode\n",
    "\n",
    "season_labeled_links = defaultdict(list)\n",
    "for link in script_links:\n",
    "    season_labeled_links[get_season(link)].append((get_episode(link), link))\n",
    "print(season_labeled_links.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEST_DIR = './data/'\n",
    "\n",
    "for season_num in season_labeled_links.keys():\n",
    "    try:\n",
    "        os.mkdir(DEST_DIR + \"season\" + str(season_num))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for season_num in season_labeled_links.keys():\n",
    "    for _, (episode_num, script_link) in enumerate(season_labeled_links[season_num]):\n",
    "        with urlopen(BASE + script_link) as res:\n",
    "            soup = BeautifulSoup(res, 'html.parser')\n",
    "            lines = soup.find('body').get_text().split('\\n')\n",
    "            lines = [line for line in lines if not any(hay in line for hay in [\n",
    "                'Written by:',\n",
    "                'Transcribed by:',\n",
    "                'Additional transcribing by:',\n",
    "                '(Note: The previously unseen parts of this episode are shown in blue text.)'\n",
    "            ])]\n",
    "            text = '\\n'.join(lines)\n",
    "            print(f\"S{season_num} E{episode_num}: EXTRACTED\")\n",
    "            with open(DEST_DIR + f\"season{str(season_num)}/episode{str(episode_num)}.txt\", 'w') as f:\n",
    "                f.write(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
